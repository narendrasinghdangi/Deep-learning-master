{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_selection\u001b[39;00m \u001b[39mimport\u001b[39;00m train_test_split\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "import torch\n",
    "import time,copy\n",
    "import math\n",
    "from sklearn.metrics import accuracy_score,f1_score\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### encoding 4 bits into one hot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encod_map(x):\n",
    "    e = np.zeros(16).astype(int)\n",
    "    index = int(\"\".join(str(y) for y in x), 2)\n",
    "    e[index] = 1\n",
    "    return  e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_vec(X):\n",
    "\n",
    "    new_X = np.zeros((X.shape[0],2**(X.shape[1])))\n",
    "    for i in range(X.shape[0]):\n",
    "        new_X[i] = encod_map(X[i])\n",
    "    # print(new_X[:2])\n",
    "    # print(np.where(np.sum(new_X,axis=1) != 1))\n",
    "    # print(np.where(np.sum(x_new_val,axis=1) != 1)\n",
    "    return new_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 16)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.random.randint(1,10,size=(10000,4))%2\n",
    "X = one_hot_vec(X)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(X)\n",
    "df.head()\n",
    "df.to_csv('./input_data.csv',index = False,header = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_sz = 16\n",
    "val_batch_sz = 64\n",
    "varience = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0    1    2    3    4    5    6    7    8    9    10   11   12   13   14  \\\n",
       "0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0   \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0   \n",
       "3  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0   \n",
       "\n",
       "    15  \n",
       "0  0.0  \n",
       "1  0.0  \n",
       "2  0.0  \n",
       "3  0.0  \n",
       "4  0.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_df = pd.read_csv(\"./input_data.csv\",header=None)\n",
    "load_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4    5    6    7    8    9   10   11   12   13   14  \\\n",
       "0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0   \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0   \n",
       "3  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0   \n",
       "\n",
       "    15  max  \n",
       "0  0.0    4  \n",
       "1  0.0   14  \n",
       "2  0.0   11  \n",
       "3  0.0    1  \n",
       "4  0.0   11  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_df['max'] = load_df.loc[:,:-1:-1].idxmax(axis = \"columns\")\n",
    "load_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df,val_df = train_test_split(load_df,test_size=0.2,random_state=4,stratify=load_df['max'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 17) (2000, 17)\n"
     ]
    }
   ],
   "source": [
    "print(train_df.shape,val_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenerateDataset(Dataset):\n",
    "  def __init__(self, data_frame,subtask):\n",
    "    self.data_frame = data_frame\n",
    "    self.subtask = subtask \n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.data_frame)\n",
    "    \n",
    "  def __getitem__(self, idx):\n",
    "      \n",
    "    if self.subtask != \"test\":\n",
    "      label = self.data_frame.iloc[idx, -1]\n",
    "    else:\n",
    "      return torch.tensor(self.data_frame.iloc[idx])\n",
    "\n",
    "    return (torch.tensor(self.data_frame.iloc[idx,:-1],dtype = float), torch.tensor(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = GenerateDataset(train_df,'train')\n",
    "val_set = GenerateDataset(val_df,'val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "       dtype=torch.float64) tensor(10)\n",
      "tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       dtype=torch.float64) tensor(6)\n"
     ]
    }
   ],
   "source": [
    "for a,b in train_set:\n",
    "    print(a,b)\n",
    "    break\n",
    "for a,b in val_set:\n",
    "    print(a,b)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9365</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1127</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9490</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1822</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4441</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3709</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8549</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3606</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8000 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0    1    2    3    4    5    6    7    8    9   10   11   12   13  \\\n",
       "9365  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0   \n",
       "1127  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "588   0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "9490  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1822  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "4441  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0   \n",
       "3709  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "8549  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "579   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0   \n",
       "3606  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "       14   15  max  \n",
       "9365  0.0  0.0   10  \n",
       "1127  1.0  0.0   14  \n",
       "588   0.0  0.0    4  \n",
       "9490  0.0  1.0   15  \n",
       "1822  0.0  1.0   15  \n",
       "...   ...  ...  ...  \n",
       "4441  0.0  0.0   10  \n",
       "3709  1.0  0.0   14  \n",
       "8549  1.0  0.0   14  \n",
       "579   0.0  0.0   13  \n",
       "3606  0.0  1.0   15  \n",
       "\n",
       "[8000 rows x 17 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_set,batch_size = train_batch_sz,shuffle = True)\n",
    "val_loader = DataLoader(val_set,batch_size = val_batch_sz,shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### backprop model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaselineBackpropModel(nn.Module):\n",
    "    def __init__(self, in_sz=16, out_sz=16, layers=[16, 7]):\n",
    "        super().__init__()\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(in_sz, layers[0]),\n",
    "            self.relu,\n",
    "            nn.Linear(layers[0], layers[1]),\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(layers[1], layers[0]),\n",
    "            self.relu,\n",
    "            nn.Linear(layers[0], out_sz),\n",
    "            nn.LogSoftmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def encode_data(self, X):\n",
    "        return self.encoder(X)\n",
    "\n",
    "    def decode_data(self, X):\n",
    "        return self.decoder(X)\n",
    "\n",
    "    def forward(self, X):\n",
    "        encoded_sig = self.encode_data(X)\n",
    "        normalized_sig = self.normalize(encoded_sig)\n",
    "        corr_sig = self.add_noise(normalized_sig)\n",
    "        decoded_sig = self.decode_data(corr_sig)\n",
    "        return decoded_sig\n",
    "\n",
    "    def normalize(self, sig):\n",
    "        normalizer = torch.zeros(sig.size()[0], 1)\n",
    "        normalizer[:, 0] = torch.linalg.norm(sig, dim=1)\n",
    "        normalizer = torch.tile(normalizer,(1,sig.size()[1]))\n",
    "        sig = torch.div(sig, normalizer)\n",
    "        sig = sig * 7\n",
    "        return sig\n",
    "\n",
    "    def add_noise(self, msg):\n",
    "        msg = msg + (varience ** 0.5) * torch.randn(*msg.size())\n",
    "        return msg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1])\n",
      "tensor([[1., 1.],\n",
      "        [3., 3.]], dtype=torch.float64)\n",
      "tensor([[10.0000, 10.0000],\n",
      "        [ 6.6667,  6.6667]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# y = torch.tensor([[1], [3]],dtype=float)\n",
    "# print(y.size())\n",
    "# # y = y.reshape(y.size()[0],1)\n",
    "# c = torch.tile(y, (1,2))\n",
    "# print(c)\n",
    "# b = torch.tensor([[10,10],[20,20]],dtype=float)\n",
    "# print(torch.div(b,c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.7417, dtype=torch.float64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.linalg.norm(torch.tensor([1,2,3],dtype=float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3.7417, 8.7750], dtype=torch.float64)\n",
      "tensor([4.1231, 5.3852, 6.7082], dtype=torch.float64)\n",
      "tensor(9.5394, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# a = torch.tensor([[1,2,3],[4,5,6]],dtype=float)\n",
    "# normalizer = torch.zeros(a.size()[0], 1)\n",
    "# print(torch.linalg.norm(a, dim=1))\n",
    "# print(torch.linalg.norm(a, dim=0))\n",
    "# print(torch.linalg.norm(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backprop = BaselineBackpropModel()\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = torch.optim.Adam(backprop.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress Bar:   0%|          | 0/10 [00:00<?, ?it/s]/home/lohith/chida/environments/basic/lib/python3.7/site-packages/torch/autograd/__init__.py:175: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 9000). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at  ../c10/cuda/CUDAFunctions.cpp:112.)\n",
      "  allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
      "Progress Bar: 100%|██████████| 10/10 [01:02<00:00,  6.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Duration: 63 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "fp = open('backprop_train.txt', \"w\")\n",
    "fp1 = open('backprop_val.txt','w')\n",
    "for i in tqdm(range(epochs),desc = \"Progress Bar\"):\n",
    "\n",
    "    trn_corr = 0\n",
    "    tst_corr = 0\n",
    "\n",
    "    for b, data in enumerate(train_loader):\n",
    "\n",
    "        b += 1\n",
    "        btch_corr = 0\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.float()\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = backprop(inputs)\n",
    "        \n",
    "        loss = criterion(y_pred,labels)\n",
    "\n",
    "        y_max = torch.argmax(y_pred,dim = 1)\n",
    "        btch_corr = torch.sum(y_max == labels)\n",
    "        trn_corr += btch_corr\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if b % 20 == 19:\n",
    "            fp.write(\n",
    "                f'epoch: {i}  train loss: {loss.item():10.8f}  train batch accuracy: {btch_corr.item()*100/(train_batch_sz):7.3f}%')\n",
    "            fp.write('\\n')\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for c,test in enumerate(val_loader):\n",
    "\n",
    "            c += 1\n",
    "\n",
    "            val_inputs,val_labels = test\n",
    "            val_inputs = val_inputs.float()\n",
    "            val_pred = backprop(val_inputs)\n",
    "            loss = criterion(val_pred,val_labels)\n",
    "\n",
    "            val_max = torch.argmax(val_pred,dim = 1)\n",
    "            tst_corr += torch.sum(val_max == val_labels)\n",
    "\n",
    "            fp1.write(\n",
    "                f'epoch: {i}  val loss: {loss.item():10.8f}  val accuracy: {tst_corr.item()*100/(val_batch_sz*c):7.3f}%')\n",
    "            fp1.write('\\n')\n",
    "\n",
    "fp.close()\n",
    "fp1.close()\n",
    "\n",
    "print(f'\\nDuration: {time.time() - start_time:.0f} seconds')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score is 1.0\n",
      "Accuracy score is 1.0\n"
     ]
    }
   ],
   "source": [
    "# Evaluation mode\n",
    "backprop.eval()\n",
    "all_labels = []\n",
    "all_predicted = []\n",
    "with torch.no_grad():\n",
    "    for data in val_loader:\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.float()\n",
    "        outputs = backprop(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        predicted = predicted.to('cpu')\n",
    "        all_labels.append(labels)\n",
    "        all_predicted.append(predicted)\n",
    "    a1,a2 = all_labels,all_predicted\n",
    "    a1 = torch.cat(a1)\n",
    "    a2 = torch.cat(a2)\n",
    "    print(f'F1 score is {np.mean(f1_score(a1,a2,average = None))}') # Printing F1 score\n",
    "    print(f'Accuracy score is {np.mean(accuracy_score(a1,a2))}') # Printing accuracy_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SPSA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpsaModel(BaselineBackpropModel):\n",
    "\n",
    "    def __init__(self, in_sz=16, out_sz=16, layers=[16, 7]):\n",
    "        super().__init__(in_sz, out_sz, layers)\n",
    "        self.criterion = nn.NLLLoss()\n",
    "\n",
    "    def stop_backprop(self):\n",
    "        for param in self.parameters():\n",
    "            param.requires_grad = False\n",
    "        return\n",
    "\n",
    "    def calculate_loss(self, inputs, lables):\n",
    "        y_pred = self.forward(inputs)\n",
    "        loss = self.criterion(y_pred, labels)\n",
    "        return loss.item()\n",
    "\n",
    "    def store_wb(self):\n",
    "        theta = []\n",
    "        delta = []\n",
    "        for param in self.parameters():\n",
    "            inter = torch.randn(*param.size())\n",
    "            inter[inter >= 0] = 1\n",
    "            inter[inter < 0] = -1\n",
    "\n",
    "            if param.dim() == 1:\n",
    "                for i in param:\n",
    "                    theta.append(i)\n",
    "                for j in inter:\n",
    "                    delta.append(j)\n",
    "\n",
    "            elif param.dim() == 2:\n",
    "                temp = torch.flatten(param)\n",
    "                for a in temp:\n",
    "                    theta.append(a)\n",
    "                \n",
    "                intrmd = torch.flatten(inter)\n",
    "                for b in intrmd:\n",
    "                    delta.append(b)\n",
    "                # for element in inter:\n",
    "                #     for i in element:\n",
    "                #         delta.append(i)\n",
    "            else:\n",
    "                raise ValueError(\"dim should be 1 or 2\")\n",
    "        return torch.from_numpy(np.array(theta)).float(), torch.from_numpy(np.array(delta)).float()\n",
    "\n",
    "    def update_parameters(self, theta, temp, factor):\n",
    "        theta.data.add_(factor*temp)\n",
    "        pos = 0\n",
    "        for names,param in self.named_parameters():\n",
    "            if \"bias\" in names:\n",
    "                var = int(param.size()[0])\n",
    "                param.data.copy_(theta[pos:(pos+var)].data)\n",
    "            elif \"weight\" in names:\n",
    "                var = int(param.size()[0] * param.size()[1])\n",
    "                temp = torch.reshape(theta[pos:(pos+var)], param.size())\n",
    "                param.data.copy_(temp.data)\n",
    "            else:\n",
    "                raise ValueError(\"dim should be 1 or 2\")\n",
    "            pos += var\n",
    "        return\n",
    "\n",
    "    def updt_spsa(self, inputs, labels, a, A, c, alpha, gamma, num_iter):\n",
    "\n",
    "        for k in range(1, num_iter):\n",
    "            theta, delta = self.store_wb()\n",
    "            saviour = theta.detach().clone()\n",
    "            lr = (a/((k+A)**alpha))\n",
    "            curr_c = (c/(k**gamma))\n",
    "            temp = curr_c * delta\n",
    "            self.update_parameters(theta, temp, 1)\n",
    "            grad = self.calculate_loss(inputs, labels)\n",
    "            self.update_parameters(theta, temp, -2)\n",
    "            grad -= self.calculate_loss(inputs, labels)\n",
    "            grad = grad/(2 * temp)\n",
    "            self.update_parameters(saviour, grad, (-1 * lr))\n",
    "        return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for names,param in spsa.named_parameters():\n",
    "#     print(names,param.dim(),*param.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpsaModel(\n",
      "  (relu): ReLU()\n",
      "  (encoder): Sequential(\n",
      "    (0): Linear(in_features=16, out_features=16, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=16, out_features=7, bias=True)\n",
      "  )\n",
      "  (decoder): Sequential(\n",
      "    (0): Linear(in_features=7, out_features=16, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=16, out_features=16, bias=True)\n",
      "    (3): LogSoftmax(dim=1)\n",
      "  )\n",
      "  (criterion): NLLLoss()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "spsa = SpsaModel()\n",
    "print(spsa)\n",
    "spsa.stop_backprop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch progress: 500it [02:23,  3.48it/s][00:00<?, ?it/s]\n",
      "spsa progress bar: 100%|██████████| 1/1 [02:24<00:00, 144.32s/it]\n"
     ]
    }
   ],
   "source": [
    "torch.autograd.set_detect_anomaly(True)\n",
    "start_time = time.time()\n",
    "epochs = 1\n",
    "num_iter = 30\n",
    "fp = open('spsa_train.txt', \"w\")\n",
    "fp1 = open('spsa_val.txt','w')\n",
    "for i in range(epochs):\n",
    "\n",
    "    spsa_trn_corr = 0\n",
    "    spsa_tst_corr = 0\n",
    "\n",
    "    for b, data in tqdm(enumerate(train_loader),desc = \"batch progress\"):\n",
    "        b += 1\n",
    "        spsa_btch_corr = 0\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.float()\n",
    "        y_pred = spsa.forward(inputs)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss = criterion(y_pred, labels)\n",
    "        y_max = torch.argmax(y_pred, dim=1)\n",
    "        spsa_btch_corr = torch.sum(y_max == labels)\n",
    "        spsa_trn_corr += spsa_btch_corr\n",
    "\n",
    "        spsa.updt_spsa(inputs, labels, 0.05, 25, 0.1, 0.9, 0.3, num_iter)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        if b % 25 == 24:\n",
    "            fp.write(\n",
    "                f'epoch: {i} train loss: {loss.item():10.8f} train batch accuracy: {spsa_btch_corr.item()*100/(train_batch_sz):7.3f}%')\n",
    "            fp.write('\\n')\n",
    "\n",
    "    for c, test in enumerate(val_loader):\n",
    "\n",
    "        c += 1\n",
    "\n",
    "        val_inputs, val_labels = test\n",
    "        val_inputs = val_inputs.float()\n",
    "        val_pred = spsa.forward(val_inputs)\n",
    "        loss = criterion(val_pred, val_labels)\n",
    "\n",
    "        val_max = torch.argmax(val_pred, dim=1)\n",
    "        spsa_tst_corr += torch.sum(val_max == val_labels)\n",
    "\n",
    "        fp1.write(\n",
    "            f'epoch: {i}  val loss: {loss.item():10.8f}  val accuracy: {spsa_tst_corr.item()*100/(val_batch_sz*c):7.3f}%')\n",
    "        fp1.write('\\n')\n",
    "\n",
    "fp.close()\n",
    "fp1.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
